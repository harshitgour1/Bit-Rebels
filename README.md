# ğŸ¤– SahaayAI â€“ A Friend That Speaks, Sees, and Signs
## Github repo : (https://github.com/harshitgour1/Bit-Rebels.git)
# Drive link : https://drive.google.com/drive/folders/1K3GQ0AmmxLmvteqeVRBhrgTEN9dl1u3m?usp=sharing

SahaayAI (from Sanskrit "SahÄya" meaning 'companion' or 'helper') is an AI-powered accessibility assistant built to empower individuals who are Deaf, Hard of Hearing, Visually Impaired, or Speech-Impaired. It brings together cutting-edge language models, computer vision, and assistive technologies into one inclusive experience.

>  A Friend That Speaks, Sees, and Signs

---

## ğŸŒŸ Features

### ğŸ–ï¸ Sign2Speak
Real-time Sign Language Recognition  
â¡ï¸ Uses computer vision and MediaPipe to recognize ASL signs  
â¡ï¸ Converts them into spoken words and readable text  
â¡ï¸ Empowers Deaf/Hard of Hearing individuals in voice-based environments

### ğŸ’¬ TalkBuddy
Text-to-Speech Assistant  
â¡ï¸ Type what you want to say  
â¡ï¸ Generates human-like speech using Google TTS or pyttsx3  
â¡ï¸ Ideal for speech-impaired individuals

### ğŸ–¼ï¸ SeeForMe
AI-Powered Visual Understanding  
â¡ï¸ Upload or capture an image  
â¡ï¸ Describes the scene using OpenAI GPT-4o & BLIP  
â¡ï¸ Text-to-Speech reads it aloud for the visually impaired

### ğŸ§­ AccessAware Navigation (Coming Soon)  
Context-aware DLIT assistant to help users navigate spaces based on their unique needs

---
!![image](https://github.com/user-attachments/assets/8241082d-59d0-4103-925e-150e7dfcd2fe)

Workflows

## Feature Workflow
### ğŸ–ï¸ *Sign2Speak* â€“ Real-Time ASL Recognition

1. *Input:* User performs ASL gestures via webcam.
2. *Recognition:* *MediaPipe* tracks hand gestures in real-time.
3. *Conversion:* Gestures are mapped to ASL signs and converted to text.
4. *Output:* Text is converted to speech using *Google TTS* or *pyttsx3*.

*Technologies:* MediaPipe, Google TTS/pyttsx3, FastAPI

![image](https://github.com/user-attachments/assets/239172ab-ef65-477d-8abb-7fe866ab5c08)

---

### ğŸ’¬ *TalkBuddy* â€“ Text-to-Speech Assistant

1. *Input:* User types text.
2. *Conversion:* Text is converted to speech by *Google TTS* or *pyttsx3*.
3. *Output:* Speech is played aloud for the user.

*Technologies:* Google TTS/pyttsx3, React.js, FastAPI

---

### ğŸ–¼ï¸ *SeeForMe* â€“ Visual Understanding for the Blind

1. *Input:* User uploads or captures an image.
2. *Processing:* *BLIP* generates a descriptive caption of the image.
3. *Output:* Caption is read aloud using *Google TTS* or *pyttsx3*.

*Technologies:* BLIP, Google TTS/pyttsx3, FastAPI

---

##  System Architecture

1. *Frontend (React.js):* Handles user input (e.g., text, images) and displays results.
2. *Backend (FastAPI):* Manages requests and processes data (e.g., sign recognition, image captioning).
3. *AI Models:* Use MediaPipe for ASL recognition and BLIP for image understanding.
4. *TTS Engine:* Converts text into speech.

---

## ğŸ’¡ Why sahaayAI?

Millions live with communication barriers every day. sahaayAI is designed to serve as:

- ğŸ—£ A voice for the speech-impaired  
- ğŸ‘€ Eyes for the blind  
- ğŸ‘‚ Understanding for the Deaf  

No more exclusion. Just accessible, adaptive, human-centered AI.

---
## ğŸ§­ SahaayAI â€“ User Flow Diagram

- ğŸ  Landing Page  
  - ğŸ”½ Feature Selection  
    - ğŸ”¹ Sign2Speak (ğŸ§)
      - ğŸ“· Activate webcam for live ASL input  
      - ğŸ“ Display recognized signs as text  
      - ğŸ”Š Convert recognized text into speech  
    - ğŸ”¹ TalkBuddy (ğŸ—£ï¸)
      - âŒ¨ï¸ User types a message  
      - ğŸ”Š Output spoken voice using TTS  
    - ğŸ”¹ SeeForMe (ğŸ–¼ï¸)
      - ğŸ“¤ Upload or capture an image  
      - ğŸ§  AI generates a description  
        - ğŸ“ Display text caption  
        - ğŸ”Š Read aloud via TTS  

  - âš™ï¸ Accessibility Settings  
    - Toggle options:
      - Font Size  
      - High Contrast Mode  
      - Keyboard-Only Navigation  
      - Voice Output Options  

  - â„¹ï¸ About / Team / Help

## ğŸ› ï¸ Tech Stack

| Layer        | Technologies                                                  |
|--------------|---------------------------------------------------------------|
| Frontend     | React.js, TailwindCSS, Axios                                  |
| Backend      | FastAPI (Python), Uvicorn, DLIT Model                         |
| AI Models    | OpenAI GPT-4o, BLIP (Image Captioning), MediaPipe for ASL     |
| TTS Engine   | Google Text-to-Speech, pyttsx3                                |
| Prototyping  | Streamlit (used for rapid UI/testing during development)      |

---

## âš™ï¸ Installation & Setup

### ğŸ“ Clone the Repo

```bash
git clone https://github.com/your-username/sahaayAI.git
cd sahaayAI
```
## Demo On Drive

ğŸ“‚ **Full Demo Files & Screenshots:**  
[View on Google Drive](https://drive.google.com/drive/folders/1K3GQ0AmmxLmvteqeVRBhrgTEN9dl1u3m?usp=sharing)
